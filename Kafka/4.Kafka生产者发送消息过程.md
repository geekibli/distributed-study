# Kafka生产者发送消息过程

首先看一下kafka生产者发送消息的架构图：

这部分只涉及到kafka整体架构中的两个部分 ， 一个是生产者模块，另一个是kafka集群模块。暂时不涉及到消费者模块。

生产者模块又分为几个重要的部分：

- 消息生产线程
  - 消息生产
  - 拦截器（可以做一些消息加工）
  - 序列化（为了追求效率，kafka实现自己的消息序列化器）
  - 消息分区器（消息该分到那个分区，在内存中完成RecordAccumulator，相当于是一个缓存队列，默认大小**32M**）
- 消息发送线程
  - 消息发送线程如何在分区器拉取消息
  - 发送到kafka集群的消息如果没有得到确认，发送线程会如何处理

![](https://oscimg.oschina.net/oscnet/up-242f1033485da703689f3d537ba895d9e4b.png)





## 重要参数

### batch.size

只有生产者DQueue批次中的数据大小达到batch.size时，sender线程才会，从DQueue中拉取数据，并发送。默认大小是**16K**

### linger.ms

如果DQueue的数据迟迟没有达到batch.size，那么，sender会在时间linger.ms后，发送数据，默认**0ms**，表示没有延迟，生产一条消息，就发送一条消息。



## 为什么kafka不使用java的序列化？

因为Java的序列化为了追求安全，增加了很多其他的数据，因此，序列化的数据大小和效率都是比较大的。而在大数据场景下，序列化的效率成为首要参考的因素。

## sender如何发送消息

首先，sender线程需要在DQueue中拉取数据，拉取的时机是什么呢？就是上面我们说到的batch.size和linger.ms两个条件来触发的。

NetworkClient在发送消息的时候，默认，每个broker，最多缓存累计5个请求，如果，这5个请求都没有得到确认，那么，将不会发送第6个消息。

kafka集群收到消息后会有确认机制。如果消息发送成功了，那么，sender线程的NetwordClient清理掉请求，并且，DQueue清楚到相关的数据。

如果没有发送成功呢，NetwordClient则会不断的重试，直到消息发送成功。retry次数默认是**Integer.MAX_VALUE**, 当然也是可以配置的。

## 消息应答机制

kafka集群收到消息之后，分区会同步数据到副本分区。

这里设计到一个消息确认机制。

- ack=0  生产者发送过来的数据，不需要等到数据落盘
- ack=1 生产者发送过来的数据，leader分区收到数据后应答
- ack=-1 生产者发送过来的数据，leader和所有的**ISR队列**里面的所有节点都收到数据后应答



## 生产者重要参数列表

| 参数名称                              | 描述                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| bootstrap.servers                     | 生产者连接集群所需的 broker 地址清单。例如 hadoop102:9092,hadoop103:9092,hadoop104:9092，可以 设置 1 个或者多个，中间用逗号隔开。注意这里并非需要所有的 broker 地址，因为生产者从给定的 broker 里查找到其他 broker 信息。 |
| key.serializer 和 value.serializer    | 指定发送消息的 key 和 value 的序列化类型。一定要写 全类名。  |
| buffer.memory                         | RecordAccumulator 缓冲区总大小，默认 32m。                   |
| batch.size                            | 缓冲区一批数据最大值，默认 **16k**。适当增加该值，可 以提高吞吐量，但是如果该值设置太大，会导致数据 传输延迟增加。 |
| linger.ms                             | 如果数据迟迟未达到 batch.size，sender 等待 linger.time 之后就会发送数据。单位 ms，默认值是 0ms，表示没 有延迟。生产环境建议该值大小为 5-100ms 之间。 |
| acks                                  | 0:生产者发送过来的数据，不需要等数据落盘应答。 1:生产者发送过来的数据，Leader 收到数据后应答。 -1(all):生产者发送过来的数据，Leader+和 isr 队列 里面的所有节点收齐数据后应答。**默认值是-1**，-1 和 all 是等价的。 |
| max.in.flight.requests.per.connection | 允许最多没有返回 ack 的次数，默认为 5，开启幂等性 要保证该值是 1-5 的数字。 |
| retries                               | 当消息发送出现错误的时候，系统会重发消息。retries 表示重试次数。默认是 int 最大值，2147483647。 如果设置了重试，还想保证消息的有序性，需要设置 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION=1 否则在重试此失败消息的时候，其他的消息可能发送 成功了。 |
| retry.backoff.ms                      | 两次重试之间的时间间隔，默认是 100ms。                       |
| enable.idempotence                    | 是否开启幂等性，默认 true，开启幂等性。                      |
| compression.type                      | 生产者发送的所有数据的压缩方式。默认是 none，也 就是不压缩。 支持压缩类型:none、gzip、snappy、lz4 和 zstd |



## Kafka异步发送

什么是异步发送和同步发送？

- 异步发送： 外部数据发送到内存的DQueue中，然后，外部数据依然可以通过生产者发送消息到DQueue。
- 同步发送：外部数据发送数据到DQueue中，消息在发送到kafka集群中，一个数据的发送才算完成，这个叫做同步发送。



生产者发送消息，**带回调函数**

回调函数会在producer收到ack时调用，为异步调用，该方法有两个参数，分别是元数据信息(RecordMetadata)和异常信息(Exception)，如果Exception为null，说明消息发送成功，如果Exception不为null，说明消息发送失败。

```java
    public static void main(String[] args) throws InterruptedException {
        // 1. 创建 kafka 生产者的配置对象
        Properties properties = new Properties();
        // 2. 给 kafka 配置对象添加配置信息
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092");
        // key,value 序列化(必须):key.serializer，value.serializer
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        // 3. 创建 kafka 生产者对象
        KafkaProducer<String, String> kafkaProducer = new KafkaProducer<String, String>(properties);
        // 4. 调用 send 方法,发送消息
        for (int i = 0; i < 5; i++) {
            // 添加回调
            kafkaProducer.send(new ProducerRecord<>("first", "atguigu " + i), new Callback() {// 该方法在Producer收到ack时调用，为异步调用 @Override
                public void onCompletion(RecordMetadata metadata, Exception exception) {
                    // 没有异常,输出信息到控制台 System.out.println(" 主 题 : " +
                    if (exception == null) {
                        metadata.topic() + "->" + "分区:" + metadata.partition());
                    } else {
                        // 出现异常打印 exception.printStackTrace();
                    }
                }
            });
            // 延迟一会会看到数据发往不同分区
            Thread.sleep(2);
        }
        // 5. 关闭资源
        kafkaProducer.close();
    }
```

消费者观察数据：

```
bin/kafka-console-consumer.sh -- bootstrap-server hadoop102:9092 --topic first

atguigu 0
atguigu 1
atguigu 2
atguigu 3
atguigu 4
```





## kafka同步发送











